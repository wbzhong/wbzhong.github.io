<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">





  
  
  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>Hexo</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhong wenbin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/" class="post-title-link" itemprop="url">Elasticsearch数据检索分析及集群搭建实战</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-08-01 15:44:05 / 修改时间：16:01:01" itemprop="dateCreated datePublished" datetime="2019-08-01T15:44:05+08:00">2019-08-01</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Elasticsearch/" itemprop="url" rel="index"><span itemprop="name">Elasticsearch</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="ES定义"><a href="#ES定义" class="headerlink" title="ES定义"></a>ES定义</h4><p>​    ES=elaticsearch简写， Elasticsearch是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。<br>​    Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。</p>
<h4 id="Lucene与ES关系"><a href="#Lucene与ES关系" class="headerlink" title="Lucene与ES关系"></a>Lucene与ES关系</h4><p>1、Lucene只是一个库。想要使用它，必须使用Java来作为开发语言并将其直接集成到你的应用中。Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。</p>
<p>2、Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。</p>
<h4 id="ES主要解决问题"><a href="#ES主要解决问题" class="headerlink" title="ES主要解决问题"></a>ES主要解决问题</h4><p>1、检索相关数据</p>
<p>2、返回统计结果</p>
<p>3、速度要快</p>
<h4 id="ES核心概念"><a href="#ES核心概念" class="headerlink" title="ES核心概念"></a>ES核心概念</h4><p>1、Cluster: 集群</p>
<p>​    代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的</p>
<p>2、Node: 节点</p>
<p>​    形成集群的每个服务器称为节点。</p>
<p>3、Shard: 分片</p>
<p>​    当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。 </p>
<p>​    当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。</p>
<p>4、Replia: 副本</p>
<p>​    es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。</p>
<p>5、Recovery:恢复</p>
<p>​    数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。</p>
<h4 id="ES数据结构"><a href="#ES数据结构" class="headerlink" title="ES数据结构"></a>ES数据结构</h4><h5 id="与关系数据库Mysql对比："><a href="#与关系数据库Mysql对比：" class="headerlink" title="与关系数据库Mysql对比："></a>与关系数据库Mysql对比：</h5><p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1557886330964.png" alt="1557886330964"></p>
<p>(1)、关系型数据库中的数据库（DataBase），等价于ES中的索引（Index）<br>(2)、一个数据库下面有N张表（Table），等价于1个索引Index下面有N多类型（Type），<br>(3)、一个数据库表（Table）下的数据由多行（ROW）多列（column，属性）组成，等价于1个Type由多个文档（Document）和多Field组成。<br>(4)、在一个关系型数据库里面，schema定义了表、每个表的字段，还有表和字段之间的关系。 与之对应的，在ES中：Mapping定义索引下的Type的字段处理规则，即索引如何建立、索引类型、是否保存原始索引JSON文档、是否压缩原始JSON文档、是否需要分词处理、如何进行分词处理等。<br>(5)、在数据库中的增insert、删delete、改update、查search操作等价于ES中的增PUT/POST、删DELETE、改UPDATE、查GET。</p>
<h5 id="Elasticsearch的数据存储"><a href="#Elasticsearch的数据存储" class="headerlink" title="Elasticsearch的数据存储"></a>Elasticsearch的数据存储</h5><p>有一篇文章解释的很好，这里就不阐述了，详情见：<a href="https://elasticsearch.cn/article/6178" target="_blank" rel="noopener">Elasticsearch中数据是如何存储的</a></p>
<h4 id="ES集群工作原理"><a href="#ES集群工作原理" class="headerlink" title="ES集群工作原理"></a>ES集群工作原理</h4><p>当ElasticSearch的节点启动后，它会利用多播(multicast)(或者单播，如果用户更改了配置)寻找集群中的其它节点，并与之建立连接。这个过程如下图所示：</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1557890748887.png" alt="1557890748887"></p>
<p>1、Elasticsearch是如何实现Master选举的？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Elasticsearch的选举是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；</span><br><span class="line"></span><br><span class="line">对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</span><br><span class="line"></span><br><span class="line">如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。</span><br><span class="line"></span><br><span class="line">当集群master候选数量不小于3个时，可以通过设置最少投票通过数量  （discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题；</span><br><span class="line"></span><br><span class="line">当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。</span><br><span class="line"></span><br><span class="line">补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</span><br></pre></td></tr></table></figure>

<p>2、详细描述一下Elasticsearch索引文档的过程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。shard = hash(document_id) % (num_of_primary_shards)</span><br><span class="line"></span><br><span class="line">当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh；</span><br><span class="line"></span><br><span class="line">当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；</span><br><span class="line"></span><br><span class="line">在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。</span><br><span class="line"></span><br><span class="line">flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；</span><br></pre></td></tr></table></figure>

<p>3、详细描述一下Elasticsearch更新和删除文档的过程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；</span><br><span class="line"></span><br><span class="line">磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。</span><br><span class="line"></span><br><span class="line">在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</span><br></pre></td></tr></table></figure>

<p>4、详细描述一下Elasticsearch搜索的过程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；</span><br><span class="line"></span><br><span class="line">在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。</span><br><span class="line"></span><br><span class="line">每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</span><br><span class="line"></span><br><span class="line">接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</span><br><span class="line"></span><br><span class="line">补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。</span><br></pre></td></tr></table></figure>

<p>5、Elasticsearch对于大数据量（上亿量级）的聚合如何实现？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关。</span><br></pre></td></tr></table></figure>

<p>6、在并发情况下，Elasticsearch如果保证读写一致？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；</span><br><span class="line">另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。</span><br><span class="line">  对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。</span><br></pre></td></tr></table></figure>

<p>7、ES如何防止因宕机造成数据丢失？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  为了防止elasticsearch宕机造成数据丢失保证可靠存储，es会将每次写入数据同时写到translog日志中。</span><br><span class="line">translog还用于提供实时CRUD。 当尝试按ID检索，更新或删除文档时，它会首先检查translog中是否有任何最近的更改，然后再尝试从相关段中检索文档。 这意味着它始终可以实时访问最新的已知文档版本</span><br></pre></td></tr></table></figure>

<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><h5 id="1、使用ES作为主要的后端"><a href="#1、使用ES作为主要的后端" class="headerlink" title="1、使用ES作为主要的后端"></a>1、使用ES作为主要的后端</h5><p>​    Elasticsearch是提供持久存储、统计等多项功能的现代搜索引擎。 新项目使用ES作为唯一的数据存储，可以保持设计尽可能简单。 此种场景不支持包含频繁更新、事务的操作。</p>
<h5 id="2、在现有系统中增加ES"><a href="#2、在现有系统中增加ES" class="headerlink" title="*2、在现有系统中增加ES"></a>*2、在现有系统中增加ES</h5><p>​    如果已经有一个在运行的复杂的系统，需求是在现有系统中添加检索服务。一种非常冒险的方式是重构系统以支持ES。而相对安全的方式是：将ES作为新的组件添加到现有系统中。<br>如果使用了如下图所示的SQL数据库和ES存储，需要找到一种方式使得两存储之间实时同步。需要根据数据的组成、数据库选择对应的同步插件。可供选择的插件包括：<br>1）mysql、oracle选择 logstash-input-jdbc 插件。<br>2）mongo选择 mongo-connector工具。</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1557891599016.png" alt="1557891599016"></p>
<h5 id="3、使用ES和现有的工具"><a href="#3、使用ES和现有的工具" class="headerlink" title="3、使用ES和现有的工具"></a>3、使用ES和现有的工具</h5><p>​    在一些情况下，不用写一行代码就能通过ES完成一项工作。很多工具都可以与ES一起工作。例如，部署大规模的日志框架存储，搜索，并分析大量数据。如流行的日志搜集分析框架ELK就是几种组件协同工作。日志记录工具除了Logstash还有Rsyslog，或Apache Flume，搜索和可视化可以使用Kibana，如下图：</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1557892000881.png" alt="1557892000881"></p>
<h4 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h4><p>此实践只测试了一些简单的索引和聚合：</p>
<p>实际情况还需要考虑的问题：</p>
<p>引入文档时mapping数据类型的配置</p>
<p>集群节点数，分区 (根据数据量考虑需要多少存储空间，需要多大的内存) 等等</p>
<h5 id="源数据"><a href="#源数据" class="headerlink" title="源数据"></a>源数据</h5><p>数据量：100万条report数据处理(mysql数据库)，示例数据如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`report`</span> <span class="keyword">VALUES</span> (<span class="string">'43345'</span>, <span class="string">'2018'</span>, <span class="string">'201809'</span>, <span class="string">'201835'</span>, <span class="string">'7'</span>, <span class="string">'43373'</span>, <span class="string">'2'</span>, <span class="string">'220000'</span>, <span class="string">'11220201'</span>, <span class="string">'20530001'</span>, <span class="string">'1118'</span>, <span class="string">'6.9010280531e+012'</span>, <span class="string">'1'</span>, <span class="string">'0'</span>, <span class="string">'0'</span>, <span class="string">'0'</span>, <span class="string">'0'</span>, <span class="string">'596.04'</span>, <span class="string">'0'</span>, <span class="string">'0'</span>, <span class="string">'0'</span>, <span class="string">'188.98'</span>, <span class="string">'1653575'</span>, <span class="string">'0'</span>, <span class="string">'0'</span>, <span class="string">'0.96'</span>, <span class="string">'8400'</span>, <span class="string">'0'</span>, <span class="string">'0'</span>, <span class="string">'5.22'</span>, <span class="string">'45675'</span>, <span class="string">'18.32'</span>,<span class="string">'2019-05-16 14:28:13'</span>;</span><br></pre></td></tr></table></figure>

<h5 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h5><h6 id="1-、部署环境"><a href="#1-、部署环境" class="headerlink" title="(1)、部署环境"></a>(1)、部署环境</h6><p>此文档为研究Elasticsearch过程中的一些实践步骤，包括ES集群搭建、logstash-input-jdbc配置等</p>
<p>系统及jdk版本：</p>
<p>centos 7.x      jdk1.8+</p>
<p>机器：</p>
<p>node-1: 192.168.100.153:9200</p>
<p>node-2: 192.168.100.154:9200</p>
<p>node-3: 192.168.100.155:9200</p>
<p>关闭防火墙：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>

<h6 id="2-、下载安装包以及jar包"><a href="#2-、下载安装包以及jar包" class="headerlink" title="(2)、下载安装包以及jar包"></a>(2)、下载安装包以及jar包</h6><p>地址：<a href="https://www.elastic.co/cn/downloads/" target="_blank" rel="noopener">https://www.elastic.co/cn/downloads/</a></p>
<p>直接在服务器上用wget命令下载速度很慢，建议在本机下载解压好放到/home/elk/目录下，需要的文件有：</p>
<p>elasticsearch-7.0.0  kibana-7.0.0-linux-x86_64  logstash-7.0.0</p>
<p>mysql-connector-java-5.1.40.jar</p>
<h6 id="3-、创建用户并赋予权限"><a href="#3-、创建用户并赋予权限" class="headerlink" title="(3)、创建用户并赋予权限"></a>(3)、创建用户并赋予权限</h6><p>由于ElasticSearch可以接收用户输入的脚本并且执行，为了系统安全考虑， 需要建立一个单独的用户用来运行ElasticSearch。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#在elasticsearch目录的父目录下创建用户</span><br><span class="line">useradd elkuser</span><br><span class="line">#赋予用户权限</span><br><span class="line">chown -R elkuser.elkuser</span><br><span class="line">#切换用户</span><br><span class="line">su elkuser</span><br></pre></td></tr></table></figure>

<h6 id="4-、修改es配置文件"><a href="#4-、修改es配置文件" class="headerlink" title="(4)、修改es配置文件"></a>(4)、修改es配置文件</h6><p>打开 elasticsearch.yml配置文件，主要修改以下配置项 （示例node-1节点，其他节点修改对应信息即可）:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 集群名称</span></span><br><span class="line"><span class="string">cluster.name:</span> <span class="string">es-cluster</span>                </span><br><span class="line"><span class="comment"># 节点名称</span></span><br><span class="line"><span class="string">node.name:</span> <span class="string">node-1</span></span><br><span class="line"><span class="comment">#path.data: /path/to/data</span></span><br><span class="line"><span class="comment">#path.logs: /path/to/logs</span></span><br><span class="line"><span class="comment"># 设置索引的分片数,默认为1  "number_of_shards" 是索引创建后一次生成的,后续不可更改设置</span></span><br><span class="line"><span class="comment"># index.number_of_shards: 1</span></span><br><span class="line"><span class="comment"># 设置索引的副本数,默认为1</span></span><br><span class="line"><span class="comment">#index.number_of_replicas: 1</span></span><br><span class="line"><span class="comment"># 主机地址</span></span><br><span class="line"><span class="string">network.host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="comment"># 端口号</span></span><br><span class="line"><span class="string">http.port:</span> <span class="number">9200</span></span><br><span class="line"><span class="comment"># 集群机器</span></span><br><span class="line"><span class="string">discovery.seed_hosts:</span> <span class="string">["192.168.100.153","192.168.100.154","192.168.100.155"]</span></span><br><span class="line"><span class="comment"># 节点配置</span></span><br><span class="line"><span class="string">cluster.initial_master_nodes:</span> <span class="string">["node-1","node-2","node-3"]</span></span><br></pre></td></tr></table></figure>

<h6 id="5-、修改系统配置"><a href="#5-、修改系统配置" class="headerlink" title="(5)、修改系统配置"></a>(5)、修改系统配置</h6><p>a、  <code>vim /etc/security/limits.conf</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 修改soft与hard的item和value值,记得把*前面的#号删掉，否则无法生效</span><br><span class="line">#&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;</span><br><span class="line">#</span><br><span class="line">*               soft    nofile          65536</span><br><span class="line">*               hard    nofile          65536</span><br></pre></td></tr></table></figure>

<p>b、 <code>vim /etc/sysctl.conf</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 添加以下内容</span><br><span class="line">vm.max_map_count=262144</span><br></pre></td></tr></table></figure>

<p>c、  执行 <code>sysctl –p</code></p>
<p>以上命令都在root用户下操作</p>
<h6 id="6-、启动elasticsearch"><a href="#6-、启动elasticsearch" class="headerlink" title="(6)、启动elasticsearch"></a>(6)、启动elasticsearch</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">三个机器操作相同</span><br><span class="line"># 切换用户</span><br><span class="line">su elkuser</span><br><span class="line"># 进入elasticsearch bin目录</span><br><span class="line">cd /home/elk/elasticsearch-7.0.0/bin</span><br><span class="line"># 启动  (后台启动 -d)</span><br><span class="line">./elasticsearch -d</span><br></pre></td></tr></table></figure>

<h6 id="7-、查看集群状态"><a href="#7-、查看集群状态" class="headerlink" title="(7)、查看集群状态"></a>(7)、查看集群状态</h6><p>访问 <code>http://192.168.100.153:9200/_cluster/health?pretty</code> 查看集群状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 返回如下内容说明集群创建成功</span><br><span class="line">&#123;</span><br><span class="line">  &quot;cluster_name&quot; : &quot;es-cluster&quot;,</span><br><span class="line">  &quot;status&quot; : &quot;green&quot;,                 #集群的状态 表示所有主副分片均正常</span><br><span class="line">  &quot;timed_out&quot; : false,          </span><br><span class="line">  &quot;number_of_nodes&quot; : 3,              #节点总数</span><br><span class="line">  &quot;number_of_data_nodes&quot; : 3,         #数据节点总数</span><br><span class="line">  &quot;active_primary_shards&quot; : 3,        #主分片数量</span><br><span class="line">  &quot;active_shards&quot; : 6,                #所有分片数量</span><br><span class="line">  &quot;relocating_shards&quot; : 0,</span><br><span class="line">  &quot;initializing_shards&quot; : 0,</span><br><span class="line">  &quot;unassigned_shards&quot; : 0,</span><br><span class="line">  &quot;delayed_unassigned_shards&quot; : 0,</span><br><span class="line">  &quot;number_of_pending_tasks&quot; : 0,</span><br><span class="line">  &quot;number_of_in_flight_fetch&quot; : 0,</span><br><span class="line">  &quot;task_max_waiting_in_queue_millis&quot; : 0,</span><br><span class="line">  &quot;active_shards_percent_as_number&quot; : 100.0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h6 id="8-、配置logstash"><a href="#8-、配置logstash" class="headerlink" title="(8)、配置logstash"></a>(8)、配置logstash</h6><p>在logstash-7.0.0目录下新建sql文件 report.sql ,内容为：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> report</span><br></pre></td></tr></table></figure>

<p>在logstash-7.0.0目录下新建配置文件 report.conf ，具体配置如下</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">input</span> <span class="string">&#123;</span></span><br><span class="line">  <span class="string">jdbc</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="comment"># 导入的jar包</span></span><br><span class="line">    <span class="string">jdbc_driver_library</span> <span class="string">=&gt;</span> <span class="string">"/home/elk/logstash-7.0.0/mysql-connector-java-5.1.40.jar"</span></span><br><span class="line">    <span class="string">jdbc_driver_class</span> <span class="string">=&gt;</span> <span class="string">"com.mysql.jdbc.Driver"</span></span><br><span class="line">    <span class="string">jdbc_connection_string</span> <span class="string">=&gt;</span> <span class="string">"jdbc:mysql://192.168.100.115:40310/test_report"</span></span><br><span class="line">    <span class="comment"># 数据库信息</span></span><br><span class="line">    <span class="string">jdbc_user</span> <span class="string">=&gt;</span> <span class="string">"*"</span> </span><br><span class="line">    <span class="string">jdbc_password</span> <span class="string">=&gt;</span> <span class="string">"*"</span></span><br><span class="line">    <span class="comment"># sql 语句文件放在相同目录下</span></span><br><span class="line">    <span class="string">statement_filepath</span> <span class="string">=&gt;</span> <span class="string">"report.sql"</span></span><br><span class="line">    <span class="comment"># 分页</span></span><br><span class="line">    <span class="string">jdbc_paging_enabled</span> <span class="string">=&gt;</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">jdbc_page_size</span> <span class="string">=&gt;</span> <span class="string">"50000"</span></span><br><span class="line">    <span class="string">type</span> <span class="string">=&gt;</span> <span class="string">"jdbc"</span></span><br><span class="line">    <span class="comment">#  tracking_column =&gt; "update_date"</span></span><br><span class="line">    <span class="comment">#  use_column_value =&gt; false</span></span><br><span class="line">    <span class="comment"># 设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新</span></span><br><span class="line">    <span class="string">schedule</span> <span class="string">=&gt;</span> <span class="string">"*/30 * * * *"</span></span><br><span class="line">    <span class="string">use_column_value</span> <span class="string">=&gt;</span> <span class="literal">false</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">output</span> <span class="string">&#123;</span></span><br><span class="line">  <span class="string">stdout</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="string">codec</span> <span class="string">=&gt;</span> <span class="string">json_lines</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line">  <span class="string">elasticsearch</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="comment"># 单点</span></span><br><span class="line">    <span class="comment"># hosts =&gt; ["192.168.100.153:9200"]</span></span><br><span class="line">    <span class="comment"># index =&gt; "report_data"</span></span><br><span class="line">    <span class="comment"># 集群</span></span><br><span class="line">    <span class="string">hosts</span> <span class="string">=&gt;</span> <span class="string">["192.168.100.153:9200","192.168.100.154:9200","192.168.100.155:9200"]</span></span><br><span class="line">    <span class="string">index</span> <span class="string">=&gt;</span> <span class="string">"report_cluster"</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>

<h6 id="9-、启动logstash"><a href="#9-、启动logstash" class="headerlink" title="(9)、启动logstash"></a>(9)、启动logstash</h6><p>在logstash-7.0.0 目录下  <code>./bin/logstash  -f   report.conf</code></p>
<p>看到以下信息则说明启动成功，等待一会便会开始从数据库中读取数据到elasticsearch文档中</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558331791515.png" alt="1558331791515"></p>
<h6 id="10-、启动kibana查看索引信息"><a href="#10-、启动kibana查看索引信息" class="headerlink" title="(10)、启动kibana查看索引信息"></a>(10)、启动kibana查看索引信息</h6><p>可以使用curl在shell中构造请求；</p>
<p>但这里采用更好的方式，在Kibana的DEV Tools中使用<em>领域特定语言</em> （DSL）， 指定构造 JSON 请求体请求。</p>
<p>访问<a href="http://192.168.100.153:5601/" target="_blank" rel="noopener">http://192.168.100.153:5601/</a> ,找到DEV Tools图标。</p>
<p>输入<code>GET /_cat/indices?v</code> 查看索引信息</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558332077042.png" alt="1558332077042"></p>
<h5 id="单点ES"><a href="#单点ES" class="headerlink" title="单点ES"></a>单点ES</h5><h6 id="1-、数据输入"><a href="#1-、数据输入" class="headerlink" title="(1)、数据输入"></a>(1)、数据输入</h6><p>导入方式：使用logstash-input-jdbc插件将数据库中数据索引到elasticsearch文档中</p>
<p>从mysql数据库索引到elasticsearch中需要的14min左右，索引文件大小201.7MB（第二次测试用时13min）</p>
<p>这是全量索引的结果，实际应用中可在logstash.conf的input中配置定时任务实现增量索引</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558157742471.png" alt="1558157742471"></p>
<h6 id="2-、数据索引"><a href="#2-、数据索引" class="headerlink" title="(2)、数据索引"></a>(2)、数据索引</h6><h6 id="a、简单索引"><a href="#a、简单索引" class="headerlink" title="a、简单索引"></a>a、简单索引</h6><p>按<code>@timestamp</code>正序索引文档，took 61ms</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558159245334.png" alt="1558159245334"></p>
<p>按<code>@timestamp</code>倒序索引文档，took 62ms</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558160098068.png" alt="1558160098068"></p>
<p>时间相减就得上了上面索引所有100万条数据的总时间为13min59s</p>
<h6 id="b、聚合索引"><a href="#b、聚合索引" class="headerlink" title="b、聚合索引"></a>b、聚合索引</h6><p>检索所有记录包含的烟草种类，相当于sql种的distinct 。这里took 3ms应该是从缓存中取得，之前已经进行过这个检索</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558160984408.png" alt="1558160984408"></p>
<p>检索各烟草品牌记录条数 took 第一次93ms,第二次3s，可见会从缓存取数据</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558162217825.png" alt="1558162217825"></p>
<p>检索不同烟草品牌年平均售出额，took 41ms</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558162986957.png" alt="1558162986957"></p>
<h5 id="ES集群"><a href="#ES集群" class="headerlink" title="ES集群"></a>ES集群</h5><h6 id="1-、集群搭建"><a href="#1-、集群搭建" class="headerlink" title="(1)、集群搭建"></a>(1)、集群搭建</h6><p>​         见步骤1</p>
<h6 id="2-、数据输入"><a href="#2-、数据输入" class="headerlink" title="(2)、数据输入"></a>(2)、数据输入</h6><p>数据索引到ES集群共用了21min 6s 。应该是每个节点多需要存储一个分片副本数据的原因</p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558165672394.png" alt="1558165672394"></p>
<p><img src="/2019/08/01/Elasticsearch数据检索分析及集群搭建实战/1558165720210.png" alt="1558165720210"></p>
<h6 id="3-、数据索引"><a href="#3-、数据索引" class="headerlink" title="(3)、数据索引"></a>(3)、数据索引</h6><p>a、简单索引</p>
<p>上面正序74ms，逆序67ms</p>
<p>b、聚合索引</p>
<p>同样进行上面那些检索的测试，发现耗时都要长一点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">#查看记录包含烟草品牌数             took 100ms</span><br><span class="line">GET /report_cluster/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;size&quot; : 0,</span><br><span class="line">    &quot;aggs&quot;: &#123;</span><br><span class="line">      &quot;distinct_brand&quot;: &#123;</span><br><span class="line">        &quot;cardinality&quot;: &#123;</span><br><span class="line">          &quot;field&quot;: &quot;brand_code&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#查看各烟草品牌记录条数      </span><br><span class="line">GET /report_cluster/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0,                     									 			 </span><br><span class="line">  &quot;aggs&quot;: &#123;                      </span><br><span class="line">    &quot;amountOfBrand&quot;: &#123;           </span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;brand_code&quot;,</span><br><span class="line">        &quot;size&quot;: 47</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#查看不同烟草品牌平均年售出金额     第一次844ms 第二次7ms</span><br><span class="line">GET /report_cluster/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0, </span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;amountOfBrand&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;brand_code&quot;,</span><br><span class="line">        &quot;size&quot;: 47</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;AvgOutSellMoneyOfYear&quot;: &#123;</span><br><span class="line">          &quot;avg&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;out_sell_money_y&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#查看不同价类的烟草在1月的总系统外销售量</span><br><span class="line">GET /sell_detail/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0, </span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;constant_score&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;range&quot;: &#123;</span><br><span class="line">          &quot;report_date&quot;: &#123;</span><br><span class="line">            &quot;gte&quot;: &quot;2019-01-01T00:00:00.000Z&quot;,</span><br><span class="line">            &quot;lt&quot;: &quot;2019-02-01T00:00:00.000Z&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;amountOfPriceType&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;pricetypecode&quot;,</span><br><span class="line">        &quot;size&quot;: 6</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;AvgOutSellAmountOf201901&quot;: &#123;</span><br><span class="line">          &quot;sum&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;out_sell_amount&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h4><p>1、<a href="https://elasticsearch.cn/article/6171" target="_blank" rel="noopener">PB级规模数据的Elasticsearch分库分表实践</a></p>
<p>2、<a href="https://www.jianshu.com/p/d7f39e445abc" target="_blank" rel="noopener">Elasticsearch百亿级实时查询优化实战</a></p>
<h4 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h4><p>1、<a href="https://blog.csdn.net/laoyang360/article/details/52244917" target="_blank" rel="noopener">Elasticsearch学习，请先看这一篇！</a></p>
<p>2、<a href="https://elasticsearch.cn/article/6178" target="_blank" rel="noopener">Elasticsearch中数据是如何存储的</a></p>
<p>3、<a href="https://www.cnblogs.com/toov5/p/10296903.html" target="_blank" rel="noopener">ElasticSearch高可用集群环境搭建和分片原理</a></p>
<p>4、[Elasticsearch: 权威指南](</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/01/初步了解分布式事务及解决方案/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhong wenbin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/08/01/初步了解分布式事务及解决方案/" class="post-title-link" itemprop="url">初步了解分布式事务及解决方案</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-08-01 10:00:25 / 修改时间：14:15:47" itemprop="dateCreated datePublished" datetime="2019-08-01T10:00:25+08:00">2019-08-01</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/分布式/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>​    在说分布式事务之前，我们先从数据库事务说起。数据库事务有四大特性：原子性(Atomicity )、一致性( Consistency )、隔离性或独立性( Isolation)和持久性(Durabilily)，简称就是ACID，这里不多说。但有一个问题，数据库在提交事务的时候突然断电，它是怎样恢复的呢？一般情况下本地数据库都会包含日志文件和数据库文件，日志文件比数据库文件大得多。数据库进行任何写入操作的时候都是要先写日志的，同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时候，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。</p>
<p>​    提出这个问题是因为分布式系统的核心就是处理各种异常情况，这也是分布式系统复杂的地方，因为分布式的网络环境很复杂，这种“断电”故障要比单机多很多，所以我们在做分布式系统的时候，最先考虑的就是这种情况。这些异常可能有 机器宕机、网络异常、存储数据丢失、其他异常等等…</p>
<p>​    数据库的四大特性已经不能满足分布式事务，于是产生了一些新的理论。</p>
<h5 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h5><p>​    CAP定理是由加州大学伯克利分校Eric Brewer教授提出来的，他指出在分布式系统中，WEB服务无法同时满足一下3个属性:</p>
<p>​    <strong>一致性(Consistency)</strong> ：对于数据分布在不同节点上的数据来说，如果在某个节点更新了数据，那么在其他节    点如果都能读取到这个最新的数据，那么就称为强一致，如果有某个节点没有读取到，那就是分布式不一致。</p>
<p>​    <strong>可用性(Availability)</strong> ： 在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）</p>
<p>​    <strong>分区容错性(Partition tolerance)</strong> ： 即使出现单个组件无法可用,操作依然可以完成</p>
<p>​    具体地讲在分布式系统中，在任何数据库设计中，一个Web应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。(CP或AP)</p>
<h5 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h5><p>​    BASE理论是用对CAP定理的进一步扩充，具体指的是：</p>
<p>​    <strong>Basically Available（基本可用）</strong>：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。<br>​    <strong>Soft state（软状态）</strong>：允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。<br>​    <strong>Eventually consistent（最终一致性）</strong>：最终一致是指经过一段时间后，所有节点数据都将会达到一致。</p>
<p>​    BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</p>
<p>​    有了上述理论基础，我们来看一些常见的分布式事务解决方案。</p>
<hr>
<h4 id="2PC（两阶段提交）"><a href="#2PC（两阶段提交）" class="headerlink" title="2PC（两阶段提交）"></a>2PC（两阶段提交）</h4><h5 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h5><p>两阶段提交使用的就是数据库事务XA协议的原理。事务管理器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交。事务协调器要求每个数据库提交数据，或者回滚数据。</p>
<h5 id="原理图"><a href="#原理图" class="headerlink" title="原理图"></a>原理图</h5><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556589824562.png" alt="1556589824562"></p>
<h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><p><strong>优点：</strong> 尽量保证了数据的强一致，适合对数据强一致要求很高的项目。（其实也不能100%保证强一致）</p>
<p><strong>缺点：</strong> 牺牲了可用性，对性能影响较大，不适合高并发高性能场景。</p>
<hr>
<h4 id="TX-LCN事务模式"><a href="#TX-LCN事务模式" class="headerlink" title="TX-LCN事务模式"></a>TX-LCN事务模式</h4><h5 id="框架背景"><a href="#框架背景" class="headerlink" title="框架背景"></a><strong>框架背景</strong></h5><p>​    LCN框架早期设计步骤为：锁定事务单元(lock)、确认事务模块状态(confirm)、通知事务(notify)，各取其首字母得名。框架从2017年6月份发布的1.0版本，到现在已经发展到了5.0.2版本。5.0以后由于框架兼容了LCN、TCC、TXC三种事务模式，改名为TX-LCN分布式事务框架。</p>
<h5 id="事务控制原理图"><a href="#事务控制原理图" class="headerlink" title="事务控制原理图"></a>事务控制原理图</h5><p>​    TX-LCN由两大模块组成, TxClient、TxManager，TxClient作为模块的依赖框架，提供TX-LCN的标准支持，TxManager作为分布式事务的控制方。事务发起方或者参与方都由TxClient端来控制。</p>
<p>原理图</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556180372396.png" alt="1556180372396"></p>
<h5 id="核心步骤"><a href="#核心步骤" class="headerlink" title="核心步骤"></a>核心步骤</h5><ul>
<li>创建事务组<br>是指在事务发起方开始执行业务代码之前先调用TxManager创建事务组对象，然后拿到事务标示GroupId的过程。</li>
<li>加入事务组<br>添加事务组是指参与方在执行完业务方法以后，将该模块的事务信息通知给TxManager的操作。</li>
<li>通知事务组<br>是指在发起方执行完业务代码以后，将发起方执行结果状态通知给TxManager,TxManager将根据事务最终状态和事务组的信息来通知相应的参与模块提交或回滚事务，并返回结果给事务发起方。</li>
</ul>
<h5 id="模式特点"><a href="#模式特点" class="headerlink" title="模式特点"></a>模式特点</h5><p>优点：</p>
<ul>
<li>该模式对代码的嵌入性较低。</li>
<li>该模式下的事务提交与回滚是由本地事务方控制，对于数据一致性上有较高的保障。</li>
<li>支持了TXC和TCC模式，可结合使用</li>
</ul>
<p>缺点：</p>
<ul>
<li>需额外部署tx-manager服务节点（有可能出现因节点出问题而带来的问题）</li>
<li>代理的连接需要随事务发起方一起释放连接，增加了连接占用的时间。</li>
</ul>
<h5 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h5><p>​    这里写了一个tx-lcn的简单demo，可在gitlab上查看或拉取下来自己尝试一下。</p>
<p>​    项目地址：<a href="http://120.79.168.253:19088/gitlab/zoomlgd/starter/tree/development/txlcn-demo" target="_blank" rel="noopener">txlcn-demo</a></p>
<hr>
<h4 id="TCC事务模式"><a href="#TCC事务模式" class="headerlink" title="TCC事务模式"></a>TCC事务模式</h4><h5 id="框架背景-1"><a href="#框架背景-1" class="headerlink" title="框架背景"></a>框架背景</h5><p>​    在08年的软件开发2.0技术大会上，支付宝程立在PPT<a href="https://wenku.baidu.com/view/be946bec0975f46527d3e104.html" target="_blank" rel="noopener">大规模SOA系统中的分布事务处理</a>，提出TCC概念。目前很多分布式事务开源项目也都是基于TCC的思想实现。</p>
<h5 id="事务控制原理图-1"><a href="#事务控制原理图-1" class="headerlink" title="事务控制原理图"></a>事务控制原理图</h5><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556589892129.png" alt="1556589892129"></p>
<p>​    事务开始时，业务应用会向事务协调器注册启动事务。之后业务应用会调用所有服务的try接口，完成一阶段准备。之后事务协调器会根据try接口返回情况，决定调用confirm接口或者cancel接口。如果接口调用失败，会进行重试。</p>
<h5 id="核心步骤-1"><a href="#核心步骤-1" class="headerlink" title="核心步骤"></a>核心步骤</h5><p>​    TCC即为Try -Confirm -Cancel，它属于补偿型分布式事务。顾名思义，TCC实现分布式事务一共有三个步骤：    <strong>Try：尝试执行业务</strong><br>​        完成所有业务检查（一致性）<br>​        预留必须业务资源（准隔离性）<br>​    <strong>Confirm：执行业务</strong><br>​        执行任务，使用Try阶段预留的业务资源，需满足幂等性<br>​    <strong>Cancel：取消执行业务</strong><br>​        取消执行业务，释放预留资源，需满足幂等性        </p>
<h5 id="tcc-transaction-源码简单分析"><a href="#tcc-transaction-源码简单分析" class="headerlink" title="tcc-transaction 源码简单分析"></a>tcc-transaction 源码简单分析</h5><h6 id="Transaction对象的属性"><a href="#Transaction对象的属性" class="headerlink" title="Transaction对象的属性"></a>Transaction对象的属性</h6><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556592153750.png" alt="1556592153750"></p>
<table>
<thead>
<tr>
<th align="left">属性</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">xid</td>
<td>全局事务id</td>
</tr>
<tr>
<td align="left">status</td>
<td>事务状态：trying,confirming,canceling</td>
</tr>
<tr>
<td align="left">transactionType</td>
<td>Root(根事务),Branch(分支事务)；事务发起方法对应主事务Root</td>
</tr>
<tr>
<td align="left">retriedCount</td>
<td>事务重试次数，当confirm或者cancel失败重试时增加</td>
</tr>
<tr>
<td align="left">createTime</td>
<td>事务创建时间</td>
</tr>
<tr>
<td align="left">lastUpdateTime</td>
<td>事务最后更新时间</td>
</tr>
<tr>
<td align="left">version</td>
<td>事务版本</td>
</tr>
<tr>
<td align="left">participants</td>
<td>事务参与者</td>
</tr>
<tr>
<td align="left">attachments</td>
<td>附加参数</td>
</tr>
</tbody></table>
<h6 id="Transaction对象的两个重要方法"><a href="#Transaction对象的两个重要方法" class="headerlink" title="Transaction对象的两个重要方法"></a>Transaction对象的两个重要方法</h6><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556593084224.png" alt="1556593084224"></p>
<p>执行Transaction对象的commit或rollback方法，会对应执行所有participant的commit或rollback方法</p>
<h6 id="TransactionManager"><a href="#TransactionManager" class="headerlink" title="TransactionManager"></a>TransactionManager</h6><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556593483540.png" alt="1556593483540"></p>
<p>TransactionManager用来控制Transaction的生命周期，Transaction的改变使用TransactionRepository同步到第三方存储，一般使用mysql数据库存储。</p>
<h6 id="重试（补偿）机制的配置"><a href="#重试（补偿）机制的配置" class="headerlink" title="重试（补偿）机制的配置"></a>重试（补偿）机制的配置</h6><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1557035993109.png" alt="1557035993109"></p>
<p>基本思路：</p>
<p>1.获取所有没被处理完的事务（具体表现为状态为confirming或cancelling）</p>
<p>2.比较最大重试次数和分支事务最大可持续时间</p>
<p>3.若confirming或cancelling成功则删除事务</p>
<p>这里可以看一下tcc-transaction框架下TCC事务的执行流程</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1557035890392.png" alt="1557035890392"></p>
<p>由此基本可以分析：TCC 事务框架都是要记录一些分布式事务的活动日志的，也就是事务记录，可以在磁盘上的日志文件里记录，也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。</p>
<h5 id="模式特点-1"><a href="#模式特点-1" class="headerlink" title="模式特点"></a>模式特点</h5><p>优点：</p>
<ul>
<li>应用可自己定义数据库操作的粒度，不会锁定整个资源，使得降低锁冲突、提高吞吐量成为可能</li>
</ul>
<p>缺点：</p>
<ul>
<li>对应用的侵入性强。业务逻辑的每个分支都需要实现try、confirm、cancel三个操作，应用侵入性较强，改造成本高。</li>
<li>实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口必须实现幂等。</li>
</ul>
<h5 id="模式比较"><a href="#模式比较" class="headerlink" title="模式比较"></a>模式比较</h5><p>​    TCC实际上把数据库层的二阶段提交上提到了应用层来实现，对于数据库来说是一阶段提交，规避了数据库层的    2PC性能低下问题。</p>
<p>​    海信HICS团队对不使用消息中间件的分布式事务处理模式进行了压力测试，结果可作公司选型参考。</p>
<p>​    它使用的是一个订单的业务场景。具体为：用户请求订单服务创建订单，订单服务作为事务发起者，发起分布式事务，订单服务分别请求库存服务与支付服务完成相应操作，从而完成一个分布式事务。</p>
<p>具体可见：<a href="http://springcloud.cn/view/374" target="_blank" rel="noopener">Spring Cloud的分布式事务框架压测第一轮</a></p>
<hr>
<h4 id="Seata（Fescar）事务模式"><a href="#Seata（Fescar）事务模式" class="headerlink" title="Seata（Fescar）事务模式"></a>Seata（Fescar）事务模式</h4><h5 id="框架背景-2"><a href="#框架背景-2" class="headerlink" title="框架背景"></a>框架背景</h5><p>TXC：淘宝分布式事务组件。 阿里巴巴中间件团队自2014年启动该项目，以满足应用程序架构从单一服务变为微服务所导致的分布式事务问题。</p>
<p>GTS：全局事务服务。 TXC作为Aliyun中间件产品，2016年更换新名称GTS。</p>
<p>FESCAR：2019年开源基于TXC / GTS的开源项目FESCAR，以便与社区密切合作，共同成长。</p>
<p>Seata：简单的可扩展分布式事务架构。Ant Financial加入Fescar，使其成为一个更加开放的分布式事务社区，Fescar将重命名为Seata。</p>
<h5 id="事务控制原理图-2"><a href="#事务控制原理图-2" class="headerlink" title="事务控制原理图"></a>事务控制原理图</h5><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556523369631.png" alt="1556523369631"></p>
<h5 id="核心组件："><a href="#核心组件：" class="headerlink" title="核心组件："></a>核心组件：</h5><p>事务协调器（TC） ：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。<br>事务管理者（TM）：全局事务管理器，控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议<br>资源管理器（RM）：控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚</p>
<p>一个典型的分布式事务过程：</p>
<ol>
<li>TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID。</li>
<li>XID 在微服务调用链路的上下文中传播。</li>
<li>RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖。</li>
<li>TM 向 TC 发起针对 XID 的全局提交或回滚决议。</li>
<li>TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。</li>
</ol>
<h5 id="事务生命周期"><a href="#事务生命周期" class="headerlink" title="事务生命周期:"></a>事务生命周期:</h5><p><strong>（1）事务发起</strong>：</p>
<p>​    1.构造一个全局事务，使用<code>@GlobalTransactional</code> 注解，由这个注解逻辑会进入到一个execute()方法中</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556617041724.png" alt="1556617041724"></p>
<p>​    2.开始事务</p>
<p>​    通过 TmRpcClient 请求TC server端,注册一个全局的事物。得到一个全局事务id:XID,将这个XID设置到上下文中</p>
<p>​    3.执行原始的业务代码</p>
<p>​    在springcloud中我们用feign去请求其他服务，seata对feign进行了重写，在SeataFeignClient中seata对每个     feign的请求都会做一次判断，如果在全局上下文中含有事务id，feign的请求头会带上XID</p>
<p>​    4.参与者在收到feign请求时，首先会被SeataHandlerInterceptor拦截器拦截，拦截器会把请求中的XID设置到    本地的全局上下文中</p>
<p><strong>（2）事务参与：</strong></p>
<p>​    1.然后参与者(分支)就开始执行本地的业务。seata在这里做了大量的背后工作。为了能在jdbc连接中添加了自己的逻辑，seata重写了Statment之前的逻辑（代理）</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556617228588.png" alt="1556617228588"></p>
<p>​    2.注册分支事务到TC server端</p>
<p>​    3.seata 的 JDBC 数据源代理通过对业务 SQL 的解析，把业务数据在更新前后的数据镜像组织成回滚日志，利    用本地事务的 ACID 特性，将业务数据的更新和回滚日志的写入在同一个本地事务中提交。这样可以保证任何提    交的业务数据的更新一定有相应的回滚日志存在。</p>
<p>​    4.最后上报分支事务的状态（成功 or 失败）</p>
<p>​    基于这样的机制，分支的本地事务便可以在全局事务的 Phase1 提交，马上释放本地事务锁定的资源。</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556615755289.png" alt="1556615755289"></p>
<p><strong>（3）事务提交或回滚</strong></p>
<p>​    <strong>全局事务提交：</strong>当全局事务中所有分支事务全部完成并且都执行成功，这时TM会发起全局事务提交,TC收到全全局事务提交消息后，会通知各分支事务进行提交，此时分支事务此时已经完成提交，不需要同步协调处理（只需要异步清理回滚日志），Phase2 可以非常快速地完成。</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556618022071.png" alt="1556618022071"></p>
<p>​    <strong>全局事务回滚：</strong>当全局事务中所有分支事务全部完成并且某个分支事务失败了，TM会通知TC协调全局事务回滚，进而TC通知各分支事务进行回滚。RM 收到协调器发来的回滚请求，通过 XID 和 Branch ID 找到相应的回滚日志记录，通过回滚记录生成反向的更新 SQL 并执行，以完成分支的回滚。</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556618125969.png" alt="1556618125969"></p>
<h5 id="模式特点-2"><a href="#模式特点-2" class="headerlink" title="模式特点"></a>模式特点</h5><p>优点：</p>
<ul>
<li>​    业务入侵几乎为零，只需要简单的配置Seata的数据代理和加个注解<code>@GlobalTransactional</code>，加一个           undo_log表</li>
<li>​    正确的协调：通过后台定时任务各种正确的重试，并且未来会推出监控平台有可能可以手动回滚。</li>
<li>​    高可用: 通过 HA-Cluster 保证高可用（2019年5月，Seata 将加入服务端 HA 集群支持）。</li>
<li>​    高性能：文件顺序写，RPC 通过 netty 实现，Seata 未来可以水平扩展，提高处理性能。</li>
<li>​    高扩展性：提供给用户可以自由实现的地方，比如配置，服务发现和注册，全局锁等等。</li>
</ul>
<p>缺点：</p>
<ul>
<li>​    需额外启动一个TC服务端来推动全局事务提交或回滚。</li>
<li>​    在Seata的RoadMap里，Seata需要在<em>v1.0.0</em>才达到生产环境使用</li>
</ul>
<p>附上Seata Wiki(包含Seata的RoadMap)地址: <a href="https://github.com/seata/seata/wiki/概览" target="_blank" rel="noopener">概览</a></p>
<h5 id="使用实例"><a href="#使用实例" class="headerlink" title="使用实例"></a>使用实例</h5><p>​    Seata开源项目上提供了多种集成的demo，很容易上手使用。</p>
<p>​    这里的使用的demo基于spring cloud+feign+spring jpa+spring cloud alibaba seata+mysql。</p>
<p>​    具体可见：<a href="https://github.com/seata/seata-samples/tree/master/springcloud-jpa-seata" target="_blank" rel="noopener">springcloud-jpa-seata</a></p>
<p>​    在实现demo时我遇到了一个错误，在官方提供的步骤里没提到，但有人在issues中提到了相同的错误。</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556529586191.png" alt="1556529586191"></p>
<p>​    解决办法：</p>
<p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556529668557.png" alt="1556529668557"></p>
<hr>
<h4 id="基于消息的最终一致性方案"><a href="#基于消息的最终一致性方案" class="headerlink" title="基于消息的最终一致性方案"></a><strong>基于消息的最终一致性方案</strong></h4><h5 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h5><p>​    消息一致性方案是通过消息中间件保证上、下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么两者都成功或者都失败。下游应用向消息系统订阅该消息，收到消息后执行相应操作。</p>
<h5 id="原理图-1"><a href="#原理图-1" class="headerlink" title="原理图"></a>原理图</h5><p><img src="/2019/08/01/初步了解分布式事务及解决方案/1556594556217.png" alt="1556594556217"></p>
<p>消息方案从本质上讲是将分布式事务转换为两个本地事务，然后依靠下游业务的重试机制达到最终一致性。基于消息的最终一致性方案对应用侵入性也很高，应用需要进行大量业务改造，成本较高。</p>
<h5 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h5><p>重试机制的基本思路：</p>
<p>​    一是定时扫描本地消息表，把未完成的消息或者失败的消息重新发送一遍；</p>
<p>​    二是设定重试次数；</p>
<p>​    三是保证操作的幂等性</p>
<p>保证幂等性常用方法：</p>
<p>1、通过唯一键值（流水号）做处理，即每次调用的时候传入唯一键值，通过唯一键值判断业务是否被操作，如果已被操作，则不再重复操作</p>
<p>2、通过状态机处理，给业务数据设置状态，通过业务状态判断是否需要重复执行</p>
<p>附上一篇讲的比较好的可靠消息最终一致性方案的文章：<a href="http://www.cnblogs.com/jajian/p/10014145.html" target="_blank" rel="noopener">可靠消息最终一致性方案的核心流程</a></p>
<hr>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p>1、 <a href="https://txlcn.org/zh-cn/index.html" target="_blank" rel="noopener">TX-LCN分布式事务框架官方文档</a></p>
<p>2、<a href="http://springcloud.cn/view/374" target="_blank" rel="noopener">Spring Cloud的分布式事务框架压测第一轮</a></p>
<p>3、<a href="http://www.cnblogs.com/jajian/p/10014145.html" target="_blank" rel="noopener">终于有人把“TCC分布式事务”实现原理讲明白了</a></p>
<p>4、<a href="https://my.oschina.net/keking/blog/3011509" target="_blank" rel="noopener">Fescar分布式事务实现原理解析探秘</a></p>
<p>5、<a href="https://github.com/seata/seata/wiki/概览" target="_blank" rel="noopener">Seata官方wiki</a></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/25/docker搭建elk/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhong wenbin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/25/docker搭建elk/" class="post-title-link" itemprop="url">docker搭建ELK日志中心</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-25 16:11:53" itemprop="dateCreated datePublished" datetime="2019-07-25T16:11:53+08:00">2019-07-25</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-08-01 16:14:14" itemprop="dateModified" datetime="2019-08-01T16:14:14+08:00">2019-08-01</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Elasticsearch/" itemprop="url" rel="index"><span itemprop="name">Elasticsearch</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Elasticsearch/ELK/" itemprop="url" rel="index"><span itemprop="name">ELK</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Elasticsearch/ELK/日志中心/" itemprop="url" rel="index"><span itemprop="name">日志中心</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="ELK简介"><a href="#ELK简介" class="headerlink" title="ELK简介"></a>ELK简介</h5><p>​    在开源的日志管理方案中，最出名的莫过于 ELK 了。ELK 是三个软件的合称：<strong>E</strong>lasticsearch、<strong>L</strong>ogstash、<strong>K</strong>ibana。Spring Cloud作为现在最热门的微服务架构，其分布式的日志输出如果使用传统方式来进行分析查看会非常麻烦，可以直接用ELK来为其日志提供友好的服务，而kafka作为现在大数据消息队列的标准可以作为Spring Cloud与ELK之间的桥梁。(本文暂不集成Kafka)</p>
<h5 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h5><p>Elasticsearch是一个基于Lucene和Restful接口的分布式搜索擎，设计目标就是要能够处理和搜索巨量的日志数据。</p>
<h5 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h5><p>读取原始日志，并对其进行分析和过滤，然后将其转发给其他组件（比如 Elasticsearch）进行索引或存储。Logstash 支持丰富的 Input 和 Output 类型，能够处理各种应用的日志。</p>
<h5 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h5><p>Kibana是一个基于 JavaScript 的 Web 图形界面程序，专门用于可视化 Elasticsearch 的数据。Kibana 能够查询 Elasticsearch 并通过丰富的图表展示结果。用户可以创建 Dashboard 来监控系统的日志。</p>
<h5 id="日志处理流程"><a href="#日志处理流程" class="headerlink" title="日志处理流程"></a>日志处理流程</h5><p>下图展示了 Docker 部署环境下典型的 ELK 日志处理流程：<img src="/2019/07/25/docker搭建elk/1557038911006.png" alt></p>
<p>Logstash 负责从各个 Docker 容器中提取日志，Logstash将日志转发到 Elasticsearch 进行索引和保存，Kibana 分析和可视化数据。</p>
<h5 id="实践流程"><a href="#实践流程" class="headerlink" title="实践流程"></a>实践流程</h5><p>ELK 的部署方案可以非常灵活，在规模较大的生产系统中，ELK 有自己的集群，实现了高可用和负载均衡。这里我们采用最小部署方案：在容器中搭建 ELK。</p>
<h5 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h5><p>通过这个地址下载安装：<a href="https://store.docker.com/editions/community/docker-ce-desktop-windows" target="_blank" rel="noopener">docker下载地址</a></p>
<p>安装完成后打开 Windows PowerShell，输入docker –version，如果正常输出docker版本就可以了</p>
<h5 id="安装ELK套件"><a href="#安装ELK套件" class="headerlink" title="安装ELK套件"></a>安装ELK套件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -it --name elk sebp/elk</span><br></pre></td></tr></table></figure>

<p>我们使用的是 <code>sebp/elk</code> 这个现成的 image，里面已经包含了整个 ELK stack。容器启动后 ELK 各组件将分别监听如下端口：</p>
<p>5601 - Kibana web 接口<br>9200 - Elasticsearch JSON 接口<br>5044 - Logstash 日志接收接口</p>
<h5 id="访问Kibana"><a href="#访问Kibana" class="headerlink" title="访问Kibana"></a>访问Kibana</h5><p>查看效果：<a href="http://localhost:5601" target="_blank" rel="noopener">http://localhost:5601</a></p>
<p><img src="/2019/07/25/docker搭建elk/1557039435082.png" alt></p>
<p>当前 Kibana 没有可显示的数据，因为当前 Elasticsearch 还没有任何日志数据。</p>
<h5 id="访问ElasticSearch"><a href="#访问ElasticSearch" class="headerlink" title="访问ElasticSearch"></a>访问ElasticSearch</h5><p>查看效果：<a href="http://localhost:9200/_search?pretty" target="_blank" rel="noopener">http://localhost:9200/_search?pretty</a></p>
<p><img src="/2019/07/25/docker搭建elk/1557039569329.png" alt></p>
<p>确实，目前 Elasticsearch 没有与日志相关的 <code>index</code>。</p>
<h5 id="使用TCP的方式"><a href="#使用TCP的方式" class="headerlink" title="使用TCP的方式"></a>使用TCP的方式</h5><p>由于sebp/elk中logstash的input的方式默认是filebeat,首先们需要进入elk容器中修改input方式。logstash默认会将etc/logstash/conf.d/中的配置文件进行整合然后启动。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it elk /bin/bash 进入容器</span><br><span class="line"> </span><br><span class="line">cd etc/logstash/conf.d/</span><br><span class="line"> </span><br><span class="line">vim 02-beats-input.conf 修改input配置</span><br><span class="line"> </span><br><span class="line">input &#123;    </span><br><span class="line">    tcp &#123;         </span><br><span class="line">        port =&gt; 5044         </span><br><span class="line">        codec =&gt; json_lines     </span><br><span class="line">        </span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">&#125; </span><br><span class="line">output&#123;  </span><br><span class="line">    elasticsearch &#123; </span><br><span class="line">    hosts =&gt; [&quot;localhost:9200&quot;] </span><br><span class="line">    </span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>保存文件退出，然后重启容器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart elk</span><br></pre></td></tr></table></figure>

<h5 id="工程pom-xml文件添加依赖"><a href="#工程pom-xml文件添加依赖" class="headerlink" title="工程pom.xml文件添加依赖"></a>工程pom.xml文件添加依赖</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;</span><br><span class="line">   &lt;version&gt;5.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<h5 id="添加logback-spring-xml"><a href="#添加logback-spring-xml" class="headerlink" title="添加logback-spring.xml"></a>添加logback-spring.xml</h5><p>在工程<code>resources</code>目录下新增<code>logback-spring.xml</code>配置文件</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;!--该日志将日志级别不同的log信息保存到不同的文件中 --&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;include resource=<span class="string">"org/springframework/boot/logging/logback/defaults.xml"</span> /&gt;</span><br><span class="line"></span><br><span class="line">    &lt;springProperty scope=<span class="string">"context"</span> name=<span class="string">"springAppName"</span></span><br><span class="line">                    source=<span class="string">"spring.application.name"</span> /&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 日志在工程中的输出位置 --&gt;</span><br><span class="line">    &lt;property name=<span class="string">"LOG_FILE"</span> value=<span class="string">"$&#123;BUILD_FOLDER:-build&#125;/$&#123;springAppName&#125;"</span> /&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 控制台的日志输出样式 --&gt;</span><br><span class="line">    &lt;property name=<span class="string">"CONSOLE_LOG_PATTERN"</span></span><br><span class="line">              value=<span class="string">"%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(---)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;"</span> /&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 控制台输出 --&gt;</span><br><span class="line">    &lt;appender name=<span class="string">"console"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span><br><span class="line">        &lt;filter <span class="class"><span class="keyword">class</span></span>=<span class="string">"ch.qos.logback.classic.filter.ThresholdFilter"</span>&gt;</span><br><span class="line">            &lt;level&gt;INFO&lt;/level&gt;</span><br><span class="line">        &lt;/filter&gt;</span><br><span class="line">        &lt;!-- 日志输出编码 --&gt;</span><br><span class="line">        &lt;encoder&gt;</span><br><span class="line">            &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt;</span><br><span class="line">            &lt;charset&gt;utf8&lt;/charset&gt;</span><br><span class="line">        &lt;/encoder&gt;</span><br><span class="line">    &lt;/appender&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 为logstash输出的JSON格式的Appender --&gt;</span><br><span class="line">    &lt;appender name=<span class="string">"logstash"</span></span><br><span class="line">              <span class="class"><span class="keyword">class</span></span>=<span class="string">"net.logstash.logback.appender.LogstashTcpSocketAppender"</span>&gt;</span><br><span class="line">        &lt;destination&gt;127.0.0.1:5044&lt;/destination&gt;</span><br><span class="line">        &lt;!-- 日志输出编码 --&gt;</span><br><span class="line">        &lt;encoder</span><br><span class="line">                <span class="class"><span class="keyword">class</span></span>=<span class="string">"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder"</span>&gt;</span><br><span class="line">            &lt;providers&gt;</span><br><span class="line">                &lt;timestamp&gt;</span><br><span class="line">                    &lt;timeZone&gt;UTC&lt;/timeZone&gt;</span><br><span class="line">                &lt;/timestamp&gt;</span><br><span class="line">                &lt;pattern&gt;</span><br><span class="line">                    &lt;pattern&gt;</span><br><span class="line">                        &#123;</span><br><span class="line">                        <span class="string">"severity"</span>: <span class="string">"%level"</span>,</span><br><span class="line">                        <span class="string">"service"</span>: <span class="string">"$&#123;springAppName:-&#125;"</span>,</span><br><span class="line">                        <span class="string">"trace"</span>: <span class="string">"%X&#123;X-B3-TraceId:-&#125;"</span>,</span><br><span class="line">                        <span class="string">"span"</span>: <span class="string">"%X&#123;X-B3-SpanId:-&#125;"</span>,</span><br><span class="line">                        <span class="string">"exportable"</span>: <span class="string">"%X&#123;X-Span-Export:-&#125;"</span>,</span><br><span class="line">                        <span class="string">"pid"</span>: <span class="string">"$&#123;PID:-&#125;"</span>,</span><br><span class="line">                        <span class="string">"thread"</span>: <span class="string">"%thread"</span>,</span><br><span class="line">                        <span class="string">"class"</span>: <span class="string">"%logger&#123;40&#125;"</span>,</span><br><span class="line">                        <span class="string">"rest"</span>: <span class="string">"%message"</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &lt;/pattern&gt;</span><br><span class="line">                &lt;/pattern&gt;</span><br><span class="line">            &lt;/providers&gt;</span><br><span class="line">        &lt;/encoder&gt;</span><br><span class="line">    &lt;/appender&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 日志输出级别 --&gt;</span><br><span class="line">    &lt;root level=<span class="string">"INFO"</span>&gt;</span><br><span class="line">        &lt;appender-ref ref=<span class="string">"console"</span> /&gt;</span><br><span class="line">        &lt;appender-ref ref=<span class="string">"logstash"</span> /&gt;</span><br><span class="line">    &lt;/root&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h5 id="启动项目工程"><a href="#启动项目工程" class="headerlink" title="启动项目工程"></a>启动项目工程</h5><p>日志就被发送到logstash中了。访问<a href="http://localhost:5601/" target="_blank" rel="noopener">http://localhost:5601/</a>可以进入kibana界面</p>
<h5 id="配置Pattern"><a href="#配置Pattern" class="headerlink" title="配置Pattern"></a>配置Pattern</h5><p>配置pattern，输入*，匹配所有数据</p>
<p>选择时间@timestamp，这样数据展示会以时间排序</p>
<h5 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h5><p>点击discover，输入服务名称 <code>feign-consumer</code>即可查看相关日志</p>
<p><img src="/2019/07/25/docker搭建elk/1557041279494.png" alt></p>
<p>访问ElasticSearch <a href="http://localhost:9200/_search?pretty" target="_blank" rel="noopener">http://localhost:9200/_search?pretty</a> 也可查找到feign-consumer相关日志信息</p>
<p><img src="/2019/07/25/docker搭建elk/1557041419125.png" alt></p>
<h5 id="整合filebeat"><a href="#整合filebeat" class="headerlink" title="整合filebeat"></a>整合filebeat</h5><p>docker run -d –name filebeat -v /etc/filebeat/filebeat.yml:/filebeat.yml  docker.elastic.co/beats/filebeat:7.0.1</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
  <p class="site-author-name" itemprop="name">Zhong wenbin</p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>













          
          
        </div>
      </div>

      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhong wenbin</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  













  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>



  

  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  

  



  




  

  

  

  

  

  

  

  

  

  

  

  

  


  

</body>
</html>
